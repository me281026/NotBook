1.1 修改IP地址
在虚拟机的命令行中输入下面的命令，即使用vi编辑器修改网卡的配置文件

vi /etc/sysconfig/network-scripts/ifcfg-ens33

这里只保留了一下重要的配置，其他的配置可选，配置的说明如下
TYPE=Ethernet             #类型为以太网
BOOTPROTO=static          #静态ip地址，即手动分配ip地址
NAME=ens33                #网卡名称
DEVICE=ens33              #网卡的设备名称为eth0
ONBOOT=yes                #开机启动网络
IPADDR=192.168.100.101    #指定具体的ip地址，要与上面配置为的NAT网络在同一个网段
NETMASK=255.255.255.0     #配置子网掩码
GATEWAY=192.168.100.2     #配置网关，VMware NAT网络的网关是该网段ip地址为2
DNS1=114.114.114.114      #配置国内的一个域名解析器
DNS2=8.8.8.8              #国外google的一个域名解析器

1.2 修改主机名
CentOS 7可以使用hostnamectl命令，直接修改主机名

hostnamectl set-hostname node-1.51doit.com
1.3 修改IP地址和主机名的映射关系
用vi编辑器修改/etc/hosts文件

vi /etc/hosts
添加一行新的映射，然后保存退出

192.168.100.101 node-1.51doit.com
1.4 关闭防火墙
CentOS 7的防火墙服务为firewalld，不再使用IPtables了

systemctl stop firewalld      #关闭防火墙服务网
systemctl disable firewalld   #设置防火墙服务开机不启动
2. 安装JDK
2.1 下载JDK8
Hadoop 3.x要求JDK的版本必须是java 8，下载地址：jdk-8u161-linux-x64.tar.gz

2.2 上传JDK安装包
使用FTP工具将下载好的JDK上传到CentOS 7上

2.3 解压JDK安装包
将JDK解压，-C选项表示解压到哪里，下面的命令表示将JDK解压到/usr/local/

tar -zxvf jdk-8u161-linux-x64.tar.gz -C /usr/local/
2.4 修改环境变量
使用vi编辑器修改/etc/profile

vi /etc/profile
在文件的最后添加JAVA_HOME并将JAVA_HOME下的bin目录添加到PATH中,修改后保存退出

export JAVA_HOME=/usr/local/jdk1.8.0_161
export PATH=$PATH:$JAVA_HOME/bin
然后重新加载环境变量，执行如下命令

source /etc/profile
3. 安装Hadoop
3.1 下载Hadoop安装包
目前最新的Hadoop版本的Hadoop 3.1.0，下载地址：hadoop-3.1.0.tar.gz

3.2 解压Hadoop安装包
将Hadoop的安装包上传到Linux后，先在根目录下创建一个/bigdata目录用于保存以后要安装的大数据相关程序

mkdir /bigdata
tar -zxvf hadoop-3.1.0.tar.gz -C /bigdata/
3.3 修改Hadoop的配置文件
进入到Hadoop的安装目录，然后查看该目录中的内容

cd /bigdata/hadoop-3.1.0/
ls -l
可以看到etc文件夹,这个是hadoop的配置文件路径,之后
hadoop的安装目录下有一个etc/hadoop/目录（注意不是Linux根目录的/etc），这个目录存放着Hadoop的配置文件，进入到/bigdata/hadoop-3.1.0/etc/hadoop/目录，查看目录下的内容

cd /bigdata/hadoop-3.1.0/etc/hadoop/
ls -l

可以看到core-site.xml,hadoop-env.xml,hdfs-site.xml,mapred-site.xml,yarn-site.xml

3.3.1 修改Hadoop的环境变量配置文件
hadoop-env.sh是Hadoop的环境变量配置文件，需要在该配置文件中指定JAVA_HOME的路径，使用vi编辑器修改该配置文件，然后保存退出

vi hadoop-env.sh
具体修改如下:export JAVA_HOME=/usr/loacl/jdk1.8.0_161

3.3.2 修改Hadoop的核心配置文件
core-site.xml是Hadoop的核心配置文件，里面可以配置HDFS（Hadoop分布式文件系统）的NameNode的地址和数据存储目录，使用vi编辑器修改该配置文件，然后保存退出

vi core-site.xml
具体修改内容如下:

<configuration>
    <!-- 指定hdfs的nameservice的地址为node-1.51doit.com,端口为9000 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node-1.51doit.com:9000</value>
    </property>
    <!-- 指定hadoop存储数据的目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/bigdata/hadoop-3.1.0/data</value>
    </property>
</configuration>

文件内容修改参考:
<configuration>
       <property>
                <name>fs.defaultFS</name>
                <value>hdfs://Master:9000</value>
       </property>
       <property>
                <name>io.file.buffer.size</name>
                <value>131072</value>
        </property>
       <property>
               <name>hadoop.tmp.dir</name>
               <value>file:/home/hadoopdir/tmp/</value>
               <description>A base for other temporary   directories.</description>
       </property>
        <property>
               <name>hadoop.proxyuser.hadoop.hosts</name>
               <value>*</value>
       </property>
       <property>
               <name>hadoop.proxyuser.hadoop.groups</name>
               <value>*</value>
       </property>
</configuration>


3.3.3 修改HDFS的配置文件
hdfs-site.xml是HDFS的配置文件，由于当前在一台机器上配置的Hadoop伪分布式，所以这里修改HDFS的副本为1即数据只保存一份，使用vi编辑器修改该配置文件，然后保存退出

vi hdfs-site.xml
具体修改内容如下:

<configuration>
    <!-- HDFS的副本为1，即数据只保存一份 -->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>

修改参考:
<configuration>
     <property>
             <name>dfs.namenode.name.dir</name>
             <value>file:///home/hadoopdir/dfs/name</value>
       </property>
      <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:///home/hadoopdir/dfs/data</value>
       </property>
       <property>
               <name>dfs.replication</name>
               <value>2</value>
        </property>
        <property>
                 <name>dfs.webhdfs.enabled</name>
                  <value>true</value>
         </property>
</configuration>


3.3.4 修改MapReduce的配置文件
mapred-site.xml里面可以配置MapReduce框架运行在YARN资源调度系统上，使用vi编辑器修改该配置文件，然后保存退出

vi mapred-site.xml
具体修改内容如下:

<configuration>
    <!-- 指定MapReduce运行在YARN上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>

修改参考:
<configuration>         
<property> 
      <name>mapreduce.framework.name</name>
          <value>yarn</value>
           </property>
          <property>
                  <name>mapreduce.jobhistory.address</name>
                  <value>Master:10020</value>
          </property>
          <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>Master:19888</value>
       </property>
 <property>
                <name>mapreduce.jobtracker.http.address</name>
                <value>Master:50030</value>
       </property>
 <property>
                <name>mapred.job.tracker</name>
                <value>Master:9001</value>
       </property>
</configuration>


3.3.5 修改YRAR的配置文件
yarn-site.xml是配置YARN的相关配置的文件，使用vi编辑器修改该配置文件，然后保存退出

vi yarn-site.xml
具体修改内容如下:

<configuration>
    <!-- 分别指定ResouceManager的地址 -->
    <property>
       <name>yarn.resourcemanager.hostname</name>
       <value>node-1.51doit.com</value>
    </property>
    <!-- 分别指定MapReduce的方式 -->
    <property>
       <name>yarn.nodemanager.aux-services</name>
       <value>mapreduce_shuffle</value>
    </property>
</configuration>

修改参考:
<configuration>

<!-- Site specific YARN configuration properties -->
        <property>
               <name>yarn.nodemanager.aux-services</name>
               <value>mapreduce_shuffle</value>
        </property>
        <property>                                                               
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
               <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
<property>
               <name>yarn.resourcemanager.hostname</name>
               <value>Master</value>
       </property>
        <property>
               <name>yarn.resourcemanager.address</name>
               <value>Master:8032</value>
       </property>
       <property>
               <name>yarn.resourcemanager.scheduler.address</name>
               <value>Master:8030</value>
       </property>
       <property>
            <name>yarn.resourcemanager.resource-tracker.address</name>
             <value>Master:8031</value>
      </property>
      <property>
              <name>yarn.resourcemanager.admin.address</name>
               <value>Master:8033</value>
       </property>
       <property>
               <name>yarn.resourcemanager.webapp.address</name>
               <value>Master:8088</value>
       </property>
</configuration>


3.3.6 将Hadoop的命令添加到系统环境变量
将Hadoop的bin和sbin目录下的命令添加到系统环境变量，这样在执行Hadoop相关的命令是，就可以在任何目录下执行了，使用vi编辑器修改/etc/proflie配置文件，在文件的最后添加环境变量，然后保存退出

vi /etc/profile
具体修改内容如下:

export JAVA_HOME=/usr/local/jdk1.8.0_161
export HADOOP_HOME=/bigdata/hadoop-3.1.0
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
重新加载环境变量，在命令行中执行如下命令

source /etc/profile
3.4 初始化Hadoop HDFS文件系统
上面五个配置文件修改完成后，就可以初始化HDFS文件系统了，在命令行中执行下面的命令

hdfs namenode -format
看到如下信息，代表NameNode被成功初始化
Storage directory /bigdata/hadoop-3.1.0/data/dfs/name has been successfully formatted 表示成功

3.5 启动Hadoop
在命令行中先执行启动HDFS的命令

start-dfs.sh
执行命令后，会发现出现如下错误：

Starting namenodes on [node-1.51doit.com]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
Starting secondary namenodes [node-1.51doit.com]
ERROR: Attempting to operate on hdfs secondarynamenode as root
ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.
出现错误的原因是Hadoop3.x不建议使用root用户启动HDSF，因为使用root启动HDFS会出现一系列隐患问题，如果就是想用root用户启动，需要在Hadoop的安装目录sbin的start-dfs.sh命令的最前面添加如下配置

HDFS_DATANODE_USER=root  
HADOOP_SECURE_DN_USER=hdfs  
HDFS_NAMENODE_USER=root  
HDFS_SECONDARYNAMENODE_USER=root
为了和生产环境保持一致，我们这里不使用root用户启动HDFS和YARN，那么就需要创建一个普通用户 使用root用户添加一个名叫bigdata的普通用户并设置密码

useradd bigdata
passwd bigdata
由于将要切换到bigdata用户，所以需要修改Hadoop的安装文件的所属用户和所属组

chown -R bigdata:bigdata /bigdata/
然后切换到bigdata用户

su bigdata
再执行start-dfs.sh启动HDFS

start-dfs.sh
发现又有新的问题产生：

Starting namenodes on [node-1.51doit.com]
node-1.51doit.com: Warning: Permanently added 'node-1.51doit.com,192.168.100.101' (ECDSA) to the list of known hosts.
node-1.51doit.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).
Starting datanodes
localhost: Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.
localhost: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).
Starting secondary namenodes [node-1.51doit.com]
node-1.51doit.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).
是因为没有配置SSH免密码登录录的问题，所以配置SSH免密码登录

ssh-keygen -t rsa
回车执行该命令后再接着三个回车 然后将公钥拷贝给自己

ssh-copy-id localhost
输入当前bigdata用户的密码，完成SSH免密码登录配置

启动HDFS

start-dfs.sh

显示
Starting namenodes on xxxxx
Starting datanodes
Starting secondary namenodes xxxxx

可以正常启动，并且执行jps命令后多了NameNode、DataNode和SecondaryNameNode进程，说明HDFS启动成功！

在启动YARN ` start-yarn.sh 可以正常启动，并且执行jps命令后多了ResourceManager、NodeManager进程，说明YARN启动成功！

4. 测试Hadoop环境
4.1 打开Hadoop HDFS的管理页面
使用浏览器访问hdfs管理界面：

192.168.100.101:50070

4.2 打开Hadoop YARN的管理页面
使用浏览器访问yarn管理界面：

192.168.100.101:8088
